################################################################
# this image meets all requirements resources to start jmeter
FROM alpine as jmeter_dependencies

# install all required dependencies
RUN apk add git bash openjdk8 python3 py3-pip maven curl py3-virtualenv
ENV POETRY_VERSION 1.8.1
RUN curl -sSL https://install.python-poetry.org > poetry-install.py
RUN python3 poetry-install.py
ENV POETRY_BIN /root/.local/bin/poetry

# base environments
ENV SOURCES /sources
ENV WDIR /jmeter
ENV BENCHMARK_DIR ${WDIR}/benchmarks

# set working directory in container
WORKDIR ${WDIR}
# get required resources from current build dir
ADD . ${SOURCES}
# install python dependencies
ENV VENV /root/.venv/bin/activate
RUN python3 -m venv /root/.venv && source ${VENV} && /root/.local/bin/poetry -C ${SOURCES} install
# clean directories
RUN cp -r ${SOURCES}/benchmarks ${BENCHMARK_DIR} && rm -rf ${SOURCES}

# configure java
ENV JAVA_ARGS -Xms4g -Xmx4g

# configure jmeter
RUN bash ${BENCHMARK_DIR}/setup_jmeter.bash
ENV JMETER="${WDIR}/jmeter/apache/bin/jmeter"

# configure file/dir server
RUN git clone https://github.com/simon-budig/woof.git
ENV WOOF "${WDIR}/woof/woof"

# configure M2U
RUN bash ${BENCHMARK_DIR}/setup_m2u.bash
ENV M2U="java -jar ${WDIR}/m2u/target/m2u.jar"

################################################################
# this image contains set of rules to start benchmark tests
FROM jmeter_dependencies AS benchmark_aio

WORKDIR ${BENCHMARK_DIR}

# api to test
ENV API="universal"

# input file to use for performance testing
ENV CSV="/jmeter/benchmarks/performance_data/universal/CSV/2022_11_16_hivemind_60M_prod_jrpc.csv"

# amount of threads
ENV JOBS=10

# amount of requests per thread (-1 for infinite)
ENV LOOPS=500

# possible options: old-style, new-style, postgres
ENV CALL_STYLE="old-style"

# address to test (default is set to default host address in docker)
ENV ADDRESS='192.168.6.122'

# port to perform tests
ENV PORT=17002

# url to postgres database (required only if CALL_STYLE = postgres)
ENV POSTGRES_URL="postgresql:///haf_block_log"

# schema in which functions to test are (required only if CALL_STYLE = postgres)
ENV POSTGRES_SCHEMA="hive"

# path to root directory of tests_api project (can be set on CI to /build/path/to/hive/tests/tests_api)
ENV ROOT_DIR="${WDIR}"

# if set, start hosting workdir after benchmarking on specified port (just one time), remember to expose that port
ENV SERVE_PORT=""

# additional arguments that will be passed to benchmarking script
ENV ADDITIONAL_ARGS="--skip-version-check"

# path to directory, where jmeter and python benchmark script will put all it's output
ENV JMETER_WORKDIR=${ROOT_DIR}/wdir

# verification is setup ready
RUN source ${VENV} && python3 -m pip list
RUN source ${VENV} && python3 benchmark.py -h
RUN source ${VENV} && python3 benchmark.py -n ${API} -l

# defines what to do after docker starts
ENTRYPOINT bash ${ROOT_DIR}/benchmarks/docker/entrypoint.bash $ADDITIONAL_ARGS
